{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q3sentimentClassificationV2_student.ipynb","provenance":[],"collapsed_sections":["duGMuRKSY-3h","0WZIxjNfZ80_"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tVzTX_Rs8F0y"},"source":["#Question 3 Predication of the Sentimental of a text reviews (Total 9 marks)\n","\n","\n","\n","*   Follow the steps in each of the section\n","*   You must complete the python codes from Task 1 to Task 5\n","*   Read the **TODO** in each of the task and complete the python codes in the **#Add code** cell.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nAqpq0XG180J"},"source":["Name:   \n","\n","Admin no:    "]},{"cell_type":"markdown","metadata":{"id":"yxJDiZ1FCP4I"},"source":["## Data preparation\n","You are given a text data that express the sentiments of the customers.<br>\n","The sentiments are label as follow:<br>\n","pos- postive   <br>\n","neg- negative   <br>\n","\n","The text data are stored in the Train folder with two subfolder pos and neg     \n","each of these subfolder contain 100 text reviews <br>\n","\n","Run the data preparation steps to format the text into the dataset."]},{"cell_type":"code","metadata":{"id":"UOHpL9HyMXeK"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data_dir_path='/content/drive/My Drive/Data/DSA2/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk \n","nltk.download('wordnet')\n","nltk.download('stopwords')"],"metadata":{"id":"616cwwP8f6gd"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HapEJaqzmcvh"},"source":["#Add code\n","#pip install module Here\n","#import module Here\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"htRhK9145z-m"},"source":["import os\n","import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wzH-t97pDqsH"},"source":["###Step 1\n","use the 100 text files in dataset/train/pos/ dir format to dataframe as follow:   \n","   \n","```\n","       Reviews                 |          labels\n","-------------------------------------------------------\n","text from file 1               |            1 \n","text from file 2               |            1 \n","text from file 3               |            1 \n","......                         |            1\n","......                         |            1\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"7Hbia0Bm50LA"},"source":["path = data_dir_path+\"dataset/train/pos/\"\n","temp = []\n","for file in os.listdir(path):\n","    with open(os.path.join(path + file), \"r\") as f:\n","        temp.append(f.readlines()[0])\n","\n","first_1000 = temp[:100]\n","print(first_1000)\n","pos = pd.DataFrame({\"reviews\": first_1000, \"labels\": list(np.ones(len(first_1000), dtype=int))})\n","pos.head()\n","pos.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_O175VhxFv7f"},"source":["###Step 2\n","use the 100 text files in dataset/train/neg/ dir format to dataframe as follow:   \n","   \n","```\n","       Reviews                 |          labels\n","-------------------------------------------------------\n","text from file 1               |            0 \n","text from file 2               |            0 \n","text from file 3               |            0 \n","......                         |            0\n","......                         |            0\n","```"]},{"cell_type":"code","metadata":{"id":"nw9Rdph_50VU"},"source":["path =  data_dir_path+\"dataset/train/neg/\"\n","temp = []\n","for file in os.listdir(path):\n","    with open(os.path.join(path + file), \"r\") as f:\n","        temp.append(f.readlines()[0])\n","        \n","first_1000 = temp[:100]\n","neg = pd.DataFrame({\"reviews\": first_1000, \"labels\": list(np.zeros(len(first_1000), dtype=int))})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ps4Z3PWPF9lZ"},"source":["###Step 3\n","Combine the 2 dataframe in Step1 and Step2  as follow:   \n","   \n","```\n","       Reviews                 |          labels\n","-------------------------------------------------------\n","text from file 1               |            1 \n","text from file 2               |            1 \n","text from file 3               |            1 \n","......                         |            ..\n","......                         |            ..\n","text from file n               |            0 \n","```"]},{"cell_type":"code","metadata":{"id":"AYvTuG1E6kbM"},"source":["train_data = pd.concat([pos, neg], ignore_index=True)\n","# train_data = pd.concat([pos, neg])\n","print(train_data.head())\n","train_data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cs6rJMGuGpNB"},"source":["###Step 4\n","use the 100 text files in dataset/test/pos/ dir format to dataframe as follow:   \n","   \n","```\n","       Reviews                 |          labels\n","-------------------------------------------------------\n","text from file 1               |            1 \n","text from file 2               |            1 \n","text from file 3               |            1 \n","......                         |            1\n","......                         |            1\n","```"]},{"cell_type":"code","metadata":{"id":"DU4eg2R450ke"},"source":["path = data_dir_path+\"dataset/test/pos/\"\n","temp = []\n","for file in os.listdir(path):\n","    with open(os.path.join(path + file), \"r\") as f:\n","        temp.append(f.readlines()[0])\n","        \n","first_1000 = temp[:100]\n","pos = pd.DataFrame({\"reviews\": first_1000, \"labels\": list(np.ones(len(first_1000), dtype=int))})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U5mpShusHFSb"},"source":["###Step 5\n","use the 100 text files in dataset/test/neg/ dir format to dataframe as follow:   \n","   \n","```\n","       Reviews                 |          labels\n","-------------------------------------------------------\n","text from file 1               |            0 \n","text from file 2               |            0 \n","text from file 3               |            0 \n","......                         |            0\n","......                         |            0\n","```"]},{"cell_type":"code","metadata":{"id":"ly25agQa6GKS"},"source":["path = data_dir_path+\"dataset/test/neg/\"\n","temp = []\n","for file in os.listdir(path):\n","    with open(os.path.join(path + file), \"r\") as f:\n","        temp.append(f.readlines()[0])\n","        \n","first_1000 = temp[:100]\n","neg = pd.DataFrame({\"reviews\": first_1000, \"labels\": list(np.zeros(len(first_1000), dtype=int))})"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5f6qdY-xHO3x"},"source":["###Step 6 \n","Combine the 2 dataframe in Step5 and Step6  as follow:   \n","   \n","```\n","       Reviews                 |          labels\n","-------------------------------------------------------\n","text from file 1               |            1 \n","text from file 2               |            1 \n","text from file 3               |            1 \n","......                         |            ..\n","......                         |            ..\n","text from file n               |            0 \n","```"]},{"cell_type":"code","metadata":{"id":"Yix9Du2i65HH"},"source":["test_data = pd.concat([pos, neg], ignore_index=True)\n","# test_data = pd.concat([pos, neg])\n","print(test_data.head)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c5bGqRVZK0n2"},"source":["train_data.labels.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6WQicEDvHxS8"},"source":["##Task 1 Tokenization ( 2 marks)\n","\n","Use the train_data and test_data to continue the rest of the tasks.<br>\n","\n","TODO:\n","\n","Use Tokenizer to perform tokenize on the train_data and test_data \"reviews\" column.<br>\n","\n","\n","\n","\n","\n","Complete the tokenization and store the result back into the train_data and test_data \"reviews\" column.\n"]},{"cell_type":"code","metadata":{"id":"7vV4XJ3VvrIB"},"source":["#Add code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pslI7FC2ILAd"},"source":["##Task 2 Remove Stop words (2 marks)\n","\n","TODO:\n","\n","Use the stop word in nltk \n","\n","\n","```\n","from nltk.corpus import stopwords  \n","stop_words = set(stopwords.words('english'))\n","```\n","\n","Based the set of stop_words remove the stop words in the train and test dataset \"reviews\" column.<br>\n","Complete the stop_words removal and store the result back into the train_data and test_data \"reviews\" column."]},{"cell_type":"code","source":["from nltk.corpus import stopwords  \n","stop_words = set(stopwords.words('english'))\n"],"metadata":{"id":"SdTCdwYjgBhD"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWGRprEfxOEl"},"source":["#Add code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B-1QmkMDKQvb"},"source":["##Task 3 Lemmatization  ( 2 marks)\n","   \n","TODO:\n","\n","Resolving words to their dictionary form    \n","\n","  \n","In the lemmatization process resolve words to their dictionary form in the train and test dataset \"reviews\" column.<br>\n","Complete the lemmatization and store the result back into the train_data and test_data \"reviews\" column.\n","\n"]},{"cell_type":"code","metadata":{"id":"KyOBn5DTxeOV"},"source":["#Add code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Jc-G9BhNSuk"},"source":["##Task 4 Remove unwanted symbols ( 1 mark)\n","TODO:\n","\n","Given  garbage = \"~`!@#$%^&*()_-+={[}]|\\:;'<,>.?/\"  \n","  \n","Remove the unwanted symbols in the train and test dataset \"reviews\" column.<br>\n","Complete the unwanted symbols removal and store the result back into the train_data and test_data \"reviews\" column.\n"]},{"cell_type":"code","metadata":{"id":"yGwEjmX5zbR7"},"source":["#Add code"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_L8MG3mhR8Wg"},"source":["##Task 5 Text Feature Extraction with TFIDF  ( 2 marks)\n","\n","TODO:\n","\n","This task is to do the text feature extraction with TFIDF for the train and test dataset \"reviews\" column.      \n","\n","The text feature extraction with TFIDF are stored in dataframe:\n","\n","train_features\n","\n","test_features\n","\n"]},{"cell_type":"code","metadata":{"id":"_9NiHiHb2xA7"},"source":["train_features = #Add code\n","test_features = #Add code\n","\n","train_labels = train_data[\"labels\"]\n","test_labels = test_data[\"labels\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ygi73aLZJ_bd"},"source":["train_features.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NhpQkq2TWpSt"},"source":["##Define a classification model\n","\n","\n","Given the LogisticRegression Classifier    \n","fit in the train dataset feature and labels for training\n","\n"]},{"cell_type":"code","metadata":{"id":"nL1TKgkSLtJa"},"source":["clf = LogisticRegression(random_state=0, solver='lbfgs')\n","clf.fit(train_features, train_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duGMuRKSY-3h"},"source":["##Do predication with the trained classifier \n","\n","use function predict(select a reviews column from test_feature)    \n","the predicted out should be 1 or 0 (Positive 1 or Negative 0)   \n","\n"]},{"cell_type":"code","metadata":{"id":"H13Osded2V4Q"},"source":["print(clf.predict(test_features.iloc[[1]]))\n","print(test_labels[1])\n","print(clf.predict(test_features.iloc[[110]]))\n","print(test_labels[110])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0WZIxjNfZ80_"},"source":["##Test the accurracy using test dataset \n","\n","Use clf.score(feature, labels) to calculate the score between 0 to 1    \n"]},{"cell_type":"code","metadata":{"id":"uLpSmDNpNBK7"},"source":["print(f\"The score for complete test reviews is: {clf.score(test_features, test_labels) * 100 } %\")"],"execution_count":null,"outputs":[]}]}