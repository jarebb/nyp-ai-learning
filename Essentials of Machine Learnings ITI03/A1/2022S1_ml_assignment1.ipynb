{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/nyp-sit/sdaai-iti103/blob/master/2021S1_ml_assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exxTxlIdTB3L",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# ITI103: Essentials of Machine Learning - Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS7fHzUeTB3M",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, you will work a data set based on [housing prices in Ames, Iowa](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). It is a modernized alternative to the well-known Boston Housing dataset. \n",
    "\n",
    "You may access the dataset from [https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignments/data/ames_house_prices_simple.csv) For a detailed description of each field (feature), you can refer to the following [file](https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignments/data/data_description.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PSXulFb9U0ck"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 200) \n",
    "pd.set_option('display.max_rows',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9CGm2OgTB3N",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 1 (2 marks)\n",
    "\n",
    "Complete the code below and answer the following: \n",
    "- How many rows and columns are there?\n",
    "- What are the different data types of the columns? \n",
    "\n",
    "_Type your answer here_\n",
    "1379 Rows\n",
    "40 Columns (0-39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O71PVNVLTB3O",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1379 entries, 0 to 1378\n",
      "Data columns (total 40 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   OverallQual    1379 non-null   int64  \n",
      " 1   GrLivArea      1379 non-null   float64\n",
      " 2   TotalBsmtSF    1379 non-null   float64\n",
      " 3   2ndFlrSF       1379 non-null   float64\n",
      " 4   1stFlrSF       1379 non-null   float64\n",
      " 5   BsmtFinSF1     1379 non-null   float64\n",
      " 6   GarageCars     1379 non-null   int64  \n",
      " 7   FullBath       1379 non-null   int64  \n",
      " 8   GarageArea     1379 non-null   float64\n",
      " 9   LotArea        1379 non-null   float64\n",
      " 10  MasVnrArea     1379 non-null   float64\n",
      " 11  YearBuilt      1379 non-null   int64  \n",
      " 12  YearRemodAdd   1379 non-null   int64  \n",
      " 13  GarageYrBlt    1379 non-null   float64\n",
      " 14  BsmtUnfSF      1379 non-null   float64\n",
      " 15  BsmtQual       1379 non-null   object \n",
      " 16  LotFrontage    1379 non-null   float64\n",
      " 17  OpenPorchSF    1379 non-null   float64\n",
      " 18  OverallCond    1379 non-null   int64  \n",
      " 19  GarageType     1379 non-null   object \n",
      " 20  WoodDeckSF     1379 non-null   float64\n",
      " 21  TotRmsAbvGrd   1379 non-null   int64  \n",
      " 22  MSSubClass     1379 non-null   int64  \n",
      " 23  MoSold         1379 non-null   int64  \n",
      " 24  BsmtExposure   1379 non-null   object \n",
      " 25  LotShape       1379 non-null   object \n",
      " 26  MSZoning       1379 non-null   object \n",
      " 27  BedroomAbvGr   1379 non-null   int64  \n",
      " 28  MasVnrType     1379 non-null   object \n",
      " 29  ExterQual      1379 non-null   object \n",
      " 30  HalfBath       1379 non-null   int64  \n",
      " 31  FireplaceQu    1379 non-null   object \n",
      " 32  KitchenQual    1379 non-null   object \n",
      " 33  Condition1     1379 non-null   object \n",
      " 34  BldgType       1379 non-null   object \n",
      " 35  SaleCondition  1379 non-null   object \n",
      " 36  Street         1379 non-null   object \n",
      " 37  PavedDrive     1379 non-null   object \n",
      " 38  SaleType       1379 non-null   object \n",
      " 39  SalePrice      1379 non-null   float64\n",
      "dtypes: float64(14), int64(11), object(15)\n",
      "memory usage: 431.1+ KB\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE\n",
    "\n",
    "# Import the data \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nyp-sit/sdaai-iti103/master/assignments/data/ames_house_prices_simple.csv')\n",
    "\n",
    "# Display value counts of each data type\n",
    "df.info()\n",
    "## END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6TH2a6mTB3T",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 2 (5 marks)\n",
    "\n",
    "Examine the column dtype and read the column description in data_description.txt.  Determine which columns are categorical. Create a list that contains the column names that are categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xOFa41z3TB3U",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "## START YOUR CODE\n",
    "\n",
    "# Get the list of column names that are object type\n",
    "categorical_cols = [*df.columns.values[np.where(df[df.columns.values].dtypes == 'object')]]\n",
    "\n",
    "# add additional column name that you think should be categorical\n",
    "categorical_cols = [*categorical_cols, \n",
    "  'MSSubClass', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', \n",
    "  'GarageYrBlt', 'MoSold']\n",
    "\n",
    "# YrSold exist in the data_description.txt, but is not part of the csv.\n",
    "# I consider the Year (YearBuilt, YearRemodAdd, GarageYrBlt) and Month (MoSold) as categorical data as I made an assumption that it's used to group data together.\n",
    "\n",
    "## END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W195EUbxU0cp"
   },
   "source": [
    "### Question 3 (8 marks)\n",
    "\n",
    "Think about the 'YearBuilt' and 'MoSold' columns (which represent the year the house is built and the month it was sold). They are of numeric (integer) type. Should you transform it?  Give your reason for the answer.\n",
    "\n",
    "If your answer is 'Yes', write the code to transform it.\n",
    "\n",
    "_Type your answer here_\n",
    "\n",
    "Yes.\n",
    "We need to tranform them so as to:\n",
    "1) Prevent Overftting later on\n",
    "2) ADD IN LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fT_wWnvsU0cq"
   },
   "outputs": [],
   "source": [
    "# Make a copy of the original dataframe and do all the processing on the copy \n",
    "# use the data for subsequent cells\n",
    "\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xj3K9pgIU0cr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique years: 109\n",
      "YearBuilt min/max range: 1880/2010\n",
      "pre-1900      21\n",
      "1901-1920     73\n",
      "1921-1930     66\n",
      "1931-1940     55\n",
      "1941-1950     73\n",
      "1951-1960    157\n",
      "1961-1970    176\n",
      "1971-1980    164\n",
      "1981-1990     60\n",
      "1991-2000    173\n",
      "2001-2010    361\n",
      "Name: YearBuiltGrouped, dtype: int64\n",
      "unique months =  12\n"
     ]
    }
   ],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "\n",
    "# find how many different years are there to decide if need to bin it\n",
    "\n",
    "# Find out how many unique years in YearBuilt\n",
    "print('unique years:', data['YearBuilt'].nunique())\n",
    "\n",
    "# Need to know the min and max range to better understand how we should cut\n",
    "print('YearBuilt min/max range: {0}/{1}'.format(data['YearBuilt'].min(),data['YearBuilt'].max()))\n",
    "\n",
    "# we can either bin the years into pre-1900, 1901-1920, 1921-1930, etc. or simple create 10 bins\n",
    "year_labels = ['pre-1900', \"1901-1920\", '1921-1930', '1931-1940', '1941-1950', \"1951-1960\", '1961-1970', '1971-1980', '1981-1990', '1991-2000', '2001-2010']\n",
    "data[\"YearBuiltGrouped\"] = pd.cut(data['YearBuilt'],[0, 1900, 1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010], labels=year_labels)\n",
    "\n",
    "print(data[\"YearBuiltGrouped\"].value_counts().sort_index())\n",
    "\n",
    "# One way to bin the months is to divide the months into different seasons, if we think there is some seasonal pattern \n",
    "print(\"unique months = \", data['MoSold'].nunique())\n",
    "\n",
    "spring = [3,4,5]\n",
    "summer = [6,7,8]\n",
    "autumn = [9,10,11]\n",
    "winter = [12,1,2]\n",
    "\n",
    "def month_to_season(month):\n",
    "    if month in spring: \n",
    "        return 'spring'\n",
    "    if month in summer:\n",
    "        return 'summer'\n",
    "    if month in autumn:\n",
    "        return 'autumn'\n",
    "    if month in winter:\n",
    "        return 'winter'\n",
    "    \n",
    "data['BinnedMoSold'] = data['MoSold'].map(month_to_season)\n",
    "\n",
    "# drop all the transformed columns\n",
    "data = data.drop(columns=['YearBuiltGrouped', 'BinnedMoSold'])\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YD_lVEr9U0cs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>Street</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>548.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>65.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Reg</td>\n",
       "      <td>RL</td>\n",
       "      <td>3</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>460.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>298.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Reg</td>\n",
       "      <td>RL</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>TA</td>\n",
       "      <td>0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>608.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>Mn</td>\n",
       "      <td>IR1</td>\n",
       "      <td>RL</td>\n",
       "      <td>3</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>642.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>IR1</td>\n",
       "      <td>RL</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>TA</td>\n",
       "      <td>0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>836.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>192.0</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>Av</td>\n",
       "      <td>IR1</td>\n",
       "      <td>RL</td>\n",
       "      <td>4</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  GrLivArea  TotalBsmtSF  2ndFlrSF  1stFlrSF  BsmtFinSF1  \\\n",
       "0            7     1710.0        856.0     854.0     856.0       706.0   \n",
       "1            6     1262.0       1262.0       0.0    1262.0       978.0   \n",
       "2            7     1786.0        920.0     866.0     920.0       486.0   \n",
       "3            7     1717.0        756.0     756.0     961.0       216.0   \n",
       "4            8     2198.0       1145.0    1053.0    1145.0       655.0   \n",
       "\n",
       "   GarageCars  FullBath  GarageArea  LotArea  MasVnrArea  YearBuilt  \\\n",
       "0           2         2       548.0   8450.0       196.0       2003   \n",
       "1           2         2       460.0   9600.0         0.0       1976   \n",
       "2           2         2       608.0  11250.0       162.0       2001   \n",
       "3           3         1       642.0   9550.0         0.0       1915   \n",
       "4           3         2       836.0  14260.0       350.0       2000   \n",
       "\n",
       "   YearRemodAdd  GarageYrBlt  BsmtUnfSF BsmtQual  LotFrontage  OpenPorchSF  \\\n",
       "0          2003       2003.0      150.0       Gd         65.0         61.0   \n",
       "1          1976       1976.0      284.0       Gd         80.0          0.0   \n",
       "2          2002       2001.0      434.0       Gd         68.0         42.0   \n",
       "3          1970       1998.0      540.0       TA         60.0         35.0   \n",
       "4          2000       2000.0      490.0       Gd         84.0         84.0   \n",
       "\n",
       "   OverallCond GarageType  WoodDeckSF  TotRmsAbvGrd  MSSubClass  MoSold  \\\n",
       "0            5     Attchd         0.0             8          60       2   \n",
       "1            8     Attchd       298.0             6          20       5   \n",
       "2            5     Attchd         0.0             6          60       9   \n",
       "3            5     Detchd         0.0             7          70       2   \n",
       "4            5     Attchd       192.0             9          60      12   \n",
       "\n",
       "  BsmtExposure LotShape MSZoning  BedroomAbvGr MasVnrType ExterQual  HalfBath  \\\n",
       "0           No      Reg       RL             3    BrkFace        Gd         1   \n",
       "1           Gd      Reg       RL             3       None        TA         0   \n",
       "2           Mn      IR1       RL             3    BrkFace        Gd         1   \n",
       "3           No      IR1       RL             3       None        TA         0   \n",
       "4           Av      IR1       RL             4    BrkFace        Gd         1   \n",
       "\n",
       "  FireplaceQu KitchenQual Condition1 BldgType SaleCondition Street PavedDrive  \\\n",
       "0        None          Gd       Norm     1Fam        Normal   Pave          Y   \n",
       "1          TA          TA      Feedr     1Fam        Normal   Pave          Y   \n",
       "2          TA          Gd       Norm     1Fam        Normal   Pave          Y   \n",
       "3          Gd          Gd       Norm     1Fam       Abnorml   Pave          Y   \n",
       "4          TA          Gd       Norm     1Fam        Normal   Pave          Y   \n",
       "\n",
       "  SaleType  SalePrice  \n",
       "0       WD   208500.0  \n",
       "1       WD   181500.0  \n",
       "2       WD   223500.0  \n",
       "3       WD   140000.0  \n",
       "4       WD   250000.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT2vnRP-TB3c",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 4 (2 marks)\n",
    "\n",
    "Use appropriate encoding for the categorical columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g2TkRE8bU0ct"
   },
   "outputs": [],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# Data with a logical ordering will be handled by OrdinalEncoder\n",
    "# We doesn't need to encode OverallQual and OverallCond as they are already in a int with running order.\n",
    "ordinalColumns = ['ExterQual', 'BsmtQual', 'BsmtExposure', 'KitchenQual', 'FireplaceQu']\n",
    "\n",
    "# Data without any logical ordering will be handled by OneHotEncoder. \n",
    "oneColumns = ['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'Condition1', ]\n",
    "\n",
    "# Using the default auto categorisation for OridnalEncoder, if unable to get good result, come back here to tweet.\n",
    "column_trans = make_column_transformer((OneHotEncoder(handle_unknown='ignore'), oneColumns),\n",
    "                                      (OrdinalEncoder(), ordinalColumns),\n",
    "                                      remainder='passthrough')\n",
    "\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48z7AaTtTB3g",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 5 (5 marks)\n",
    "- Separate your data into features and target label ('SalePrice') columns. \n",
    "- Create train/test splits. Decide on the most appropriate splitting strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1DhyLUwlTB3h",
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data.drop('SalePrice', axis=1)\n",
    "labels = data['SalePrice'].copy()\n",
    "\n",
    "# Pass in the Random state to ensure that our test and train data will never change. \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=9)\n",
    "## END YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dBHECC6NTB3k",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 6 (7 marks)\n",
    "\n",
    "* Scale the all the numerical (non categorical) features using one of the following: `StandardScaler`, `MinMaxScaler`\n",
    "* Be sure to fit the scaler on *ONLY* the training data, but then apply it to both the train and test data identically.\n",
    "* Optional: You may also want to calculate the skewness of your numeric features and decide if you need to do log transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "df6zIjVMU0cw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GrLivArea', 'TotalBsmtSF', '2ndFlrSF', '1stFlrSF', 'BsmtFinSF1', 'GarageArea', 'LotArea', 'MasVnrArea', 'GarageYrBlt', 'BsmtUnfSF', 'LotFrontage', 'OpenPorchSF', 'WoodDeckSF']\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].dtype == np.float64:\n",
    "        numeric_cols.append(col)\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "giZnzvCYU0cx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GrLivArea       1.367761\n",
      "TotalBsmtSF     1.751901\n",
      "2ndFlrSF        0.810282\n",
      "1stFlrSF        1.461749\n",
      "BsmtFinSF1      1.825757\n",
      "GarageArea      0.787995\n",
      "LotArea        11.662063\n",
      "MasVnrArea      2.660570\n",
      "GarageYrBlt    -0.634782\n",
      "BsmtUnfSF       0.951913\n",
      "LotFrontage     3.082204\n",
      "OpenPorchSF     2.154667\n",
      "WoodDeckSF      1.537001\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.74427699, -0.13550519,  1.5334027 , ..., -0.22523636,\n",
       "         0.16627021, -0.75529574],\n",
       "       [-0.53818252,  0.40435267, -0.7919565 , ...,  0.02141247,\n",
       "        -0.74020992, -0.75529574],\n",
       "       [ 1.28071807,  1.94104351, -0.7919565 , ...,  2.31409652,\n",
       "        -0.74020992,  1.6258011 ],\n",
       "       ...,\n",
       "       [-1.18806455, -0.35279238, -0.7919565 , ..., -0.89471176,\n",
       "        -0.74020992, -0.12244608],\n",
       "       [-0.4881916 , -0.039182  , -0.7919565 , ...,  0.83698701,\n",
       "        -0.48337389,  2.1241702 ],\n",
       "       [ 0.18860862, -0.03694193, -0.7919565 , ..., -0.85947622,\n",
       "        -0.74020992, -0.75529574]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# num_pipeline = Pipeline([('std_scaler', StandardScaler())])\n",
    "# full_pipeline = ColumnTransformer([('num', num_pipeline, numeric_cols)])\n",
    "# X_train = full_pipeline.fit_transform(X_train)\n",
    "# X_train\n",
    "\n",
    "print(X_train[numeric_cols].skew())\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X=X_train[numeric_cols], )\n",
    "# newData\n",
    "# StandardScalar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxkzAdLIU0cy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVnd4iNPTB3p"
   },
   "source": [
    "### Question 7 (5 marks)\n",
    "\n",
    "* Fit a Linear Regression model on the training data. Apply regularization if necessary. \n",
    "* Calculate the mean squared error on both the train and test set\n",
    "* Calculate the R-square error on both train and test set \n",
    "\n",
    "What can you conclude from the result? \n",
    "\n",
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFD0lAnOTB3q"
   },
   "outputs": [],
   "source": [
    "## START YOUR CODE HERE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "## END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x_-ito9U0c0"
   },
   "source": [
    "### Question 8 (5 marks)\n",
    "\n",
    "* Now train a RandomForestRegressor by using `RandomForestRegressor(n_estimators=30)`\n",
    "* Find the MSE and R-sqaure score on both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-5fCYaqU0c1"
   },
   "outputs": [],
   "source": [
    "## START YOUR CODE HERE ##\n",
    "\n",
    "\n",
    "\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4Xl4cCnTB3t",
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "### Question 9 (2 marks)\n",
    "\n",
    "Plot predicted prices vs actual prices for the RandomForestRegressor model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tda-WcgeU0c2"
   },
   "outputs": [],
   "source": [
    "## START YOUR CODE HERE ## \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "## END YOUR CODE HERE ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7P0amO1xTB3w"
   },
   "source": [
    "### Question 10 (2 marks)\n",
    "\n",
    "What can you conclude from the plot?\n",
    "\n",
    "_Type your answer here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xa_s7NSlU0c3"
   },
   "source": [
    "### Question 11 (2 marks)\n",
    "\n",
    "Noticed that we did not ask you to evaluate the result on the validation set, as our train set is pretty small (less than 1000 samples). We can however, use K-fold cross-validation to evaluate our model. \n",
    "\n",
    "- Use 5-fold cross-validation to train and evaluate our model (use RandomForestRegressor)\n",
    "- Compute the average MSEs across all folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqC456ORU0c4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# We use enumerate() to return also the index position of the list so that we can print out the fold number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4WKIc9xU0c4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "2021S1 ml_assignment1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "name": "Train_Test_Splits_Regularization_Exercises-ANSWERS",
  "notebookId": 2125319687183944,
  "vscode": {
   "interpreter": {
    "hash": "2ee0d1ec691014468da1751452785851cd50b706b6309b20431a3e39d37061ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
